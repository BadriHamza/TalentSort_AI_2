{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume=pd.read_csv('raw_data/Data_Set_CV_Cleaned_version test.csv')\n",
    "df_resume.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df_resume=df_resume.rename(columns={'New_Category':'Category','CV_cleaned':'Resume'})\n",
    "df_resume.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume['lenght']=df_resume['Resume'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4977.59805873569"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume['lenght'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='lenght', ylabel='Count'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtmUlEQVR4nO3de3SV1Z3/8U/u4XYSAuQcogkXlUu4iIKGUy8ViASMFyRripYB6lBUGqiAIpMpAuJ04jBWGTWKMz9MnCmUyiwvFSkaguAoASGKXAJZYGlDDSdhxCSgkoRk//7oyqmnSVCSk5yTzfu11rNWzt77PM/32SThs85+nichxhgjAAAAS4UGugAAAID2RNgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALBaeKALCAYNDQ0qKytTjx49FBISEuhyAADA92CM0ZkzZ5SQkKDQ0JY/vyHsSCorK1NiYmKgywAAAK1w4sQJXX755S32E3Yk9ejRQ9JfJsvhcAS4GgAA8H1UV1crMTHR+/94Swg7knfpyuFwEHYAAOhkvusSFC5QBgAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsFtCws2LFCoWEhPhsQ4YM8fafO3dOmZmZ6tWrl7p3766MjAyVl5f77KO0tFTp6enq2rWr4uPjtXjxYp0/f76jTwUAAASpgD9BediwYdq6dav3dXj4X0tauHCh3n77bW3cuFExMTGaN2+epk6dqg8//FCSVF9fr/T0dLlcLu3cuVMnT57UzJkzFRERoX/5l3/p8HMBAADBJ+BhJzw8XC6Xq0l7VVWV1q5dq/Xr12v8+PGSpNzcXA0dOlS7du3S2LFj9e6776q4uFhbt26V0+nUqFGj9MQTT2jJkiVasWKFIiMjmz1mTU2NampqvK+rq6vb5+QAAEDABfyanaNHjyohIUEDBw7U9OnTVVpaKkkqKipSXV2dUlNTvWOHDBmipKQkFRYWSpIKCws1YsQIOZ1O75i0tDRVV1fr0KFDLR4zOztbMTEx3o2/eA4AgL0CGnZSUlKUl5enLVu26MUXX9Tx48d100036cyZM/J4PIqMjFRsbKzPe5xOpzwejyTJ4/H4BJ3G/sa+lmRlZamqqsq7nThxwr8nBgAAgkZAl7EmT57s/XrkyJFKSUlRv3799Oqrr6pLly7tdtyoqChFRUW12/4BAEDwCPgy1rfFxsZq0KBBOnbsmFwul2pra1VZWekzpry83HuNj8vlanJ3VuPr5q4DAgAAl56AX6D8bWfPntVnn32mGTNmaPTo0YqIiFBBQYEyMjIkSSUlJSotLZXb7ZYkud1u/fKXv1RFRYXi4+MlSfn5+XI4HEpOTg7YeeDiTZ/9gMpOVTZpT+gTq3VrX+r4ggAA1gho2HnkkUd0xx13qF+/fiorK9Py5csVFhame++9VzExMZo9e7YWLVqkuLg4ORwOzZ8/X263W2PHjpUkTZw4UcnJyZoxY4ZWrVolj8ejpUuXKjMzk2WqTqbsVKWcty9o2r5pdYfXAgCwS0DDzp///Gfde++9+uKLL9SnTx/deOON2rVrl/r06SNJeuaZZxQaGqqMjAzV1NQoLS1NL7zwgvf9YWFh2rRpk+bOnSu3261u3bpp1qxZWrlyZaBOCQAABJkQY4wJdBGBVl1drZiYGFVVVcnhcAS6nEvSuDunNfvJTvmm1Xrvd7/t+IIAAEHv+/7/HVQXKAMAAPgbYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBq4YEuALiQI4eLNe7Oac32JfSJ1bq1L3VwRQCAzoawg6BWZ0LlvH1Bs31lm1Z3aC0AgM6JZSwAAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWC1ows6TTz6pkJAQLViwwNt27tw5ZWZmqlevXurevbsyMjJUXl7u877S0lKlp6era9euio+P1+LFi3X+/PkOrh4AAASroAg7e/bs0UsvvaSRI0f6tC9cuFBvvfWWNm7cqB07dqisrExTp0719tfX1ys9PV21tbXauXOnXnnlFeXl5WnZsmUdfQoAACBIBTzsnD17VtOnT9d//ud/qmfPnt72qqoqrV27Vk8//bTGjx+v0aNHKzc3Vzt37tSuXbskSe+++66Ki4v161//WqNGjdLkyZP1xBNPKCcnR7W1tS0es6amRtXV1T4bAACwU8DDTmZmptLT05WamurTXlRUpLq6Op/2IUOGKCkpSYWFhZKkwsJCjRgxQk6n0zsmLS1N1dXVOnToUIvHzM7OVkxMjHdLTEz081kBAIBgEdCws2HDBn388cfKzs5u0ufxeBQZGanY2FifdqfTKY/H4x3z7aDT2N/Y15KsrCxVVVV5txMnTrTxTAAAQLAKD9SBT5w4oYceekj5+fmKjo7u0GNHRUUpKiqqQ48JAAACI2Cf7BQVFamiokLXXnutwsPDFR4erh07dujZZ59VeHi4nE6namtrVVlZ6fO+8vJyuVwuSZLL5Wpyd1bj68YxAADg0hawsDNhwgQdOHBA+/bt825jxozR9OnTvV9HRESooKDA+56SkhKVlpbK7XZLktxutw4cOKCKigrvmPz8fDkcDiUnJ3f4OQEAgOATsGWsHj16aPjw4T5t3bp1U69evbzts2fP1qJFixQXFyeHw6H58+fL7XZr7NixkqSJEycqOTlZM2bM0KpVq+TxeLR06VJlZmayTAUAACQFMOx8H88884xCQ0OVkZGhmpoapaWl6YUXXvD2h4WFadOmTZo7d67cbre6deumWbNmaeXKlQGsGgAABJOgCjvbt2/3eR0dHa2cnBzl5OS0+J5+/fpp8+bN7VwZAADorAL+nB0AAID2RNgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUCGnZefPFFjRw5Ug6HQw6HQ263W7///e+9/efOnVNmZqZ69eql7t27KyMjQ+Xl5T77KC0tVXp6urp27ar4+HgtXrxY58+f7+hTAQAAQSqgYefyyy/Xk08+qaKiIu3du1fjx4/XXXfdpUOHDkmSFi5cqLfeeksbN27Ujh07VFZWpqlTp3rfX19fr/T0dNXW1mrnzp165ZVXlJeXp2XLlgXqlAAAQJAJD+TB77jjDp/Xv/zlL/Xiiy9q165duvzyy7V27VqtX79e48ePlyTl5uZq6NCh2rVrl8aOHat3331XxcXF2rp1q5xOp0aNGqUnnnhCS5Ys0YoVKxQZGdnscWtqalRTU+N9XV1d3X4nCQAAAiportmpr6/Xhg0b9NVXX8ntdquoqEh1dXVKTU31jhkyZIiSkpJUWFgoSSosLNSIESPkdDq9Y9LS0lRdXe39dKg52dnZiomJ8W6JiYntd2IAACCgAh52Dhw4oO7duysqKkoPPvigXn/9dSUnJ8vj8SgyMlKxsbE+451OpzwejyTJ4/H4BJ3G/sa+lmRlZamqqsq7nThxwr8nBQAAgkZAl7EkafDgwdq3b5+qqqr0P//zP5o1a5Z27NjRrseMiopSVFRUux4DAAAEh4CHncjISF155ZWSpNGjR2vPnj3693//d02bNk21tbWqrKz0+XSnvLxcLpdLkuRyufTRRx/57K/xbq3GMQAA4NIW8GWsv9XQ0KCamhqNHj1aERERKigo8PaVlJSotLRUbrdbkuR2u3XgwAFVVFR4x+Tn58vhcCg5ObnDawcAAMEnoJ/sZGVlafLkyUpKStKZM2e0fv16bd++Xe+8845iYmI0e/ZsLVq0SHFxcXI4HJo/f77cbrfGjh0rSZo4caKSk5M1Y8YMrVq1Sh6PR0uXLlVmZibLVAAAQFKAw05FRYVmzpypkydPKiYmRiNHjtQ777yjW2+9VZL0zDPPKDQ0VBkZGaqpqVFaWppeeOEF7/vDwsK0adMmzZ07V263W926ddOsWbO0cuXKQJ0SAAAIMgENO2vXrr1gf3R0tHJycpSTk9PimH79+mnz5s3+Lg0AAFgi4BcoA6115HCxxt05rUl7Qp9YrVv7UgAqAgAEI8IOOq06Eyrn7QuatJdtWt3htQAAglfQ3Y0FAADgT60KOwMHDtQXX3zRpL2yslIDBw5sc1EAAAD+0qqw88c//lH19fVN2mtqavT555+3uSgAAAB/uahrdn73u995v258Fk6j+vp6FRQUqH///n4rDgAAoK0uKuxMmTJFkhQSEqJZs2b59EVERKh///761a9+5bfiAAAA2uqiwk5DQ4MkacCAAdqzZ4969+7dLkUBAAD4S6tuPT9+/Li/6wAAAGgXrX7OTkFBgQoKClRRUeH9xKfRyy+/3ObCAAAA/KFVYefxxx/XypUrNWbMGPXt21chISH+rgsAAMAvWhV21qxZo7y8PM2YMcPf9QAAAPhVq56zU1tbqx/84Af+rgUAAMDvWhV2fvrTn2r9+vX+rgUAAMDvWrWMde7cOf3Hf/yHtm7dqpEjRyoiIsKn/+mnn/ZLcQAAAG3VqrCzf/9+jRo1SpJ08OBBnz4uVgYAAMGkVWHnvffe83cdAAAA7aJV1+wAAAB0Fq36ZGfcuHEXXK7atm1bqwsCAADwp1aFncbrdRrV1dVp3759OnjwYJM/EAoAABBIrQo7zzzzTLPtK1as0NmzZ9tUEAAAgD/59Zqdv//7v+fvYgEAgKDi17BTWFio6Ohof+4SAACgTVq1jDV16lSf18YYnTx5Unv37tVjjz3ml8IAAAD8oVVhJyYmxud1aGioBg8erJUrV2rixIl+KQwAAMAfWhV2cnNz/V0HAABAu2hV2GlUVFSkw4cPS5KGDRuma665xi9FAQAA+Eurwk5FRYXuuecebd++XbGxsZKkyspKjRs3Ths2bFCfPn38WSMAAECrtepurPnz5+vMmTM6dOiQTp8+rdOnT+vgwYOqrq7Wz3/+c3/XCAAA0Gqt+mRny5Yt2rp1q4YOHeptS05OVk5ODhcoAwCAoNKqT3YaGhoUERHRpD0iIkINDQ1tLgoAAMBfWhV2xo8fr4ceekhlZWXets8//1wLFy7UhAkT/FYcAABAW7VqGev555/XnXfeqf79+ysxMVGSdOLECQ0fPly//vWv/Vog7DJ99gMqO1XZpL3k6DE5O74cAMAloFVhJzExUR9//LG2bt2qI0eOSJKGDh2q1NRUvxYH+5SdqpTz9gVN2g+setBvxzhyuFjj7pzWpD2hT6zWrX3Jb8cBAHQOFxV2tm3bpnnz5mnXrl1yOBy69dZbdeutt0qSqqqqNGzYMK1Zs0Y33XRTuxQLfB91JrTZQFW2aXWH1wIACLyLumZn9erVmjNnjhwOR5O+mJgYPfDAA3r66af9VhwAAEBbXVTY+fTTTzVp0qQW+ydOnKiioqI2FwUAAOAvFxV2ysvLm73lvFF4eLhOnTrV5qIAAAD85aLCzmWXXaaDBw+22L9//3717du3zUUBAAD4y0WFndtuu02PPfaYzp0716Tvm2++0fLly3X77bf7rTgAAIC2uqi7sZYuXarXXntNgwYN0rx58zR48GBJ0pEjR5STk6P6+nr94he/aJdCAQAAWuOiwo7T6dTOnTs1d+5cZWVlyRgjSQoJCVFaWppycnLkdPJoOAAAEDwu+qGC/fr10+bNm/Xll1/q2LFjMsboqquuUs+ePdujPgAAgDZp1ROUJalnz5667rrr/FkLAACA37XqD4ECAAB0FoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUCGnays7N13XXXqUePHoqPj9eUKVNUUlLiM+bcuXPKzMxUr1691L17d2VkZKi8vNxnTGlpqdLT09W1a1fFx8dr8eLFOn/+fEeeCgAACFIBDTs7duxQZmamdu3apfz8fNXV1WnixIn66quvvGMWLlyot956Sxs3btSOHTtUVlamqVOnevvr6+uVnp6u2tpa7dy5U6+88ory8vK0bNmyQJwSAAAIMuGBPPiWLVt8Xufl5Sk+Pl5FRUW6+eabVVVVpbVr12r9+vUaP368JCk3N1dDhw7Vrl27NHbsWL377rsqLi7W1q1b5XQ6NWrUKD3xxBNasmSJVqxYocjIyECcGgAACBJBdc1OVVWVJCkuLk6SVFRUpLq6OqWmpnrHDBkyRElJSSosLJQkFRYWasSIEXI6nd4xaWlpqq6u1qFDh5o9Tk1Njaqrq302AABgp6AJOw0NDVqwYIFuuOEGDR8+XJLk8XgUGRmp2NhYn7FOp1Mej8c75ttBp7G/sa852dnZiomJ8W6JiYl+PhsAABAsArqM9W2ZmZk6ePCgPvjgg3Y/VlZWlhYtWuR9XV1dTeC5BBw5XKxxd05r0p7QJ1br1r4UgIoAAB0hKMLOvHnztGnTJr3//vu6/PLLve0ul0u1tbWqrKz0+XSnvLxcLpfLO+ajjz7y2V/j3VqNY/5WVFSUoqKi/HwWCHZ1JlTO2xc0aS/btLrDawEAdJyALmMZYzRv3jy9/vrr2rZtmwYMGODTP3r0aEVERKigoMDbVlJSotLSUrndbkmS2+3WgQMHVFFR4R2Tn58vh8Oh5OTkjjkRAAAQtAL6yU5mZqbWr1+vN998Uz169PBeYxMTE6MuXbooJiZGs2fP1qJFixQXFyeHw6H58+fL7XZr7NixkqSJEycqOTlZM2bM0KpVq+TxeLR06VJlZmby6Q0AAAhs2HnxxRclSbfccotPe25urn7yk59Ikp555hmFhoYqIyNDNTU1SktL0wsvvOAdGxYWpk2bNmnu3Llyu93q1q2bZs2apZUrV3bUaQAAgCAW0LBjjPnOMdHR0crJyVFOTk6LY/r166fNmzf7szQAAGCJoLn1HAAAoD0QdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrhQe6AHQO02c/oLJTlU3aE/rEat3alzq+IAAAvifCDr6XslOVct6+oGn7ptUdXgsAABeDZSwAAGA1PtmxAEtMAAC0jLBjAZaYAABoGctYAADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVeKjgJYgnLgMALiWEnUsQT1wGAFxKWMYCAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA17say2JHDxRp357Qm7SVHj8kZgHoAAAgEwo7F6kxos7eYH1j1YMcXAwBAgBB2AqSlB/tJPNwvWPBvBAB2IOwESEsP9pNafrhfS//5sizVNhda7rt54fPNvocHMAJA50HY6URaCkgsS7UNy30AYDfuxgIAAFYj7AAAAKsRdgAAgNUIOwAAwGqEHQAAYDXCDgAAsBphBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYLTzQBaCpI4eLNe7OaU3aS44ekzMA9aCplv6NEvrEat3alwJQEQCgJYSdIFRnQuW8fUGT9gOrHuz4YtCslv6Nyjat7vBaAAAXxjIWAACwWkDDzvvvv6877rhDCQkJCgkJ0RtvvOHTb4zRsmXL1LdvX3Xp0kWpqak6evSoz5jTp09r+vTpcjgcio2N1ezZs3X27NkOPAt7NC7NNLeVHD0W6PIAAGiVgC5jffXVV7r66qv1D//wD5o6dWqT/lWrVunZZ5/VK6+8ogEDBuixxx5TWlqaiouLFR0dLUmaPn26Tp48qfz8fNXV1em+++7T/fffr/Xr13f06XR6LS3NSCyhAQA6r4CGncmTJ2vy5MnN9hljtHr1ai1dulR33XWXJOm//uu/5HQ69cYbb+iee+7R4cOHtWXLFu3Zs0djxoyRJD333HO67bbb9NRTTykhIaHDzgUAAASnoL1m5/jx4/J4PEpNTfW2xcTEKCUlRYWFhZKkwsJCxcbGeoOOJKWmpio0NFS7d+9ucd81NTWqrq722QAAgJ2C9m4sj8cjSXI6fW+2djqd3j6Px6P4+Hif/vDwcMXFxXnHNCc7O1uPP/64nysGuCUdAIJR0Iad9pSVlaVFixZ5X1dXVysxMTGAFcEW3JIOAMEnaJexXC6XJKm8vNynvby83NvncrlUUVHh03/+/HmdPn3aO6Y5UVFRcjgcPhsAALBT0IadAQMGyOVyqaCgwNtWXV2t3bt3y+12S5LcbrcqKytVVFTkHbNt2zY1NDQoJSWlw2sGAADBJ6DLWGfPntWxY399fsvx48e1b98+xcXFKSkpSQsWLNA///M/66qrrvLeep6QkKApU6ZIkoYOHapJkyZpzpw5WrNmjerq6jRv3jzdc8893IkFAAAkBTjs7N27V+PGjfO+bryOZtasWcrLy9Ojjz6qr776Svfff78qKyt14403asuWLd5n7EjSunXrNG/ePE2YMEGhoaHKyMjQs88+2+HnAgAAglNAw84tt9wiY0yL/SEhIVq5cqVWrlzZ4pi4uDgeIAgAAFoUtNfsAAAA+ANhBwAAWI2wAwAArEbYAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBAABWI+wAAACrEXYAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFgtPNAFoHM7crhY4+6c1qQ9oU+s1q19KQAVAQDgi7CDNqkzoXLevqBJe9mm1R1eCwAAzWEZCwAAWI1PdtAuWlreKjl6TM4A1AMAuHQRdtAuWlreOrDqwY4vBgBwSSPsAB2AC7kBIHAIO0AH4EJuAAgcLlAGAABWI+wAAACrEXYAAIDVCDsAAMBqXKAMBBB3aQFA+yPsAAHEXVoA0P5YxgIAAFbjk512Nn32Ayo7VdmknT+bAABAxyDstLOyU5X82QRcNK7lAQD/IewAQYhreQDAf7hmBwAAWI2wAwAArMYyFtCJtHQtj8T1PADQEsIO0Im0dC2PxPU8ANASlrEAAIDVCDsAAMBqhB0AAGA1wg4AALAaYQcAAFiNu7EAy7X099m4VR3ApYKwA1iupb/Pxq3qAC4VLGMBAACr8ckOgHbDEhqAYEDYAdBuWEIDEAxYxgIAAFYj7AAAAKsRdgAAgNW4Zge4RB05XKxxd05r0v6nPxxVv4FXfe92iQuOAQQ3wg5wiaozoc1ePHxg1YMX1S5xwTGA4EbYAdBptXRru8SnTQD+irADoNNq6dZ2iU+bAPwVYQewREvX4JQcPSZnkB27pfF8GgOgPRB2AEtc6BqcYDt2S+O3/dv9hCAAfkfYARA0WgpBLEkBaAueswMAAKxmTdjJyclR//79FR0drZSUFH300UeBLgkAAAQBK5axfvvb32rRokVas2aNUlJStHr1aqWlpamkpETx8fGBLg9AJ8Zfbgc6PyvCztNPP605c+bovvvukyStWbNGb7/9tl5++WX94z/+Y4CrA9BWrbnTzF9PiC45ekw3L3y+SXtLF1N3xJOmAxnALvbYtj8LiTDcOXT6sFNbW6uioiJlZWV520JDQ5WamqrCwsJm31NTU6Oamhrv66qqKklSdXW13+s7X1enum++atLe0FDfbPuF+gLVTk3Bc+xgrKkjjlFTbxQ3YU6T9nMHF7RYU0vv+fTgAl1zEe0tHeNi9y9JpVteaPb3zE8zH9LJ/6tq0n7ij58psf8VTdqPfvYH3ZD5VJP2rc/+XDdNntrssVva18W2X+yxWxovtTwfgdTSv0Xf3jH6fzn/3qS9tOyU4if9rGl7EJ5bR7jY+Wurxjk2xlx4oOnkPv/8cyPJ7Ny506d98eLF5vrrr2/2PcuXLzeS2NjY2NjY2CzYTpw4ccGs0Ok/2WmNrKwsLVq0yPu6oaFBp0+fVq9evRQSEuK341RXVysxMVEnTpyQw+Hw234vJcxh2zGH/sE8th1z2HbMoS9jjM6cOaOEhIQLjuv0Yad3794KCwtTeXm5T3t5eblcLlez74mKilJUVJRPW2xsbHuVKIfDwTdlGzGHbccc+gfz2HbMYdsxh38VExPznWM6/a3nkZGRGj16tAoKCrxtDQ0NKigokNvtDmBlAAAgGHT6T3YkadGiRZo1a5bGjBmj66+/XqtXr9ZXX33lvTsLAABcuqwIO9OmTdOpU6e0bNkyeTwejRo1Slu2bJHT2d5//vDCoqKitHz58iZLZvj+mMO2Yw79g3lsO+aw7ZjD1gkx5rvu1wIAAOi8Ov01OwAAABdC2AEAAFYj7AAAAKsRdgAAgNUIO+0oJydH/fv3V3R0tFJSUvTRRx8FuqSAWLFihUJCQny2IUOGePvPnTunzMxM9erVS927d1dGRkaTh0SWlpYqPT1dXbt2VXx8vBYvXqzz58/7jNm+fbuuvfZaRUVF6corr1ReXl5HnF67eP/993XHHXcoISFBISEheuONN3z6jTFatmyZ+vbtqy5duig1NVVHjx71GXP69GlNnz5dDodDsbGxmj17ts6ePeszZv/+/brpppsUHR2txMRErVq1qkktGzdu1JAhQxQdHa0RI0Zo8+bNfj/f9vBdc/iTn/ykyfflpEmTfMZc6nOYnZ2t6667Tj169FB8fLymTJmikpISnzEd+fPbGX+nfp85vOWWW5p8Lz744IM+Yy7lOfQLv/yBKjSxYcMGExkZaV5++WVz6NAhM2fOHBMbG2vKy8sDXVqHW758uRk2bJg5efKkdzt16pS3/8EHHzSJiYmmoKDA7N2714wdO9b84Ac/8PafP3/eDB8+3KSmpppPPvnEbN682fTu3dtkZWV5x/zhD38wXbt2NYsWLTLFxcXmueeeM2FhYWbLli0deq7+snnzZvOLX/zCvPbaa0aSef311336n3zySRMTE2PeeOMN8+mnn5o777zTDBgwwHzzzTfeMZMmTTJXX3212bVrl/nf//1fc+WVV5p7773X219VVWWcTqeZPn26OXjwoPnNb35junTpYl566SXvmA8//NCEhYWZVatWmeLiYrN06VITERFhDhw40O5z0FbfNYezZs0ykyZN8vm+PH36tM+YS30O09LSTG5urjl48KDZt2+fue2220xSUpI5e/asd0xH/fx21t+p32cOf/jDH5o5c+b4fC9WVVV5+y/1OfQHwk47uf76601mZqb3dX19vUlISDDZ2dkBrCowli9fbq6++upm+yorK01ERITZuHGjt+3w4cNGkiksLDTG/OU/rdDQUOPxeLxjXnzxReNwOExNTY0xxphHH33UDBs2zGff06ZNM2lpaX4+m473t/9RNzQ0GJfLZf7t3/7N21ZZWWmioqLMb37zG2OMMcXFxUaS2bNnj3fM73//exMSEmI+//xzY4wxL7zwgunZs6d3Do0xZsmSJWbw4MHe1z/60Y9Menq6Tz0pKSnmgQce8Os5treWws5dd93V4nuYw6YqKiqMJLNjxw5jTMf+/NryO/Vv59CYv4Sdhx56qMX3MIdtxzJWO6itrVVRUZFSU1O9baGhoUpNTVVhYWEAKwuco0ePKiEhQQMHDtT06dNVWloqSSoqKlJdXZ3PXA0ZMkRJSUneuSosLNSIESN8HhKZlpam6upqHTp0yDvm2/toHGPjfB8/flwej8fnfGNiYpSSkuIzZ7GxsRozZox3TGpqqkJDQ7V7927vmJtvvlmRkZHeMWlpaSopKdGXX37pHWPzvG7fvl3x8fEaPHiw5s6dqy+++MLbxxw2VVVVJUmKi4uT1HE/vzb9Tv3bOWy0bt069e7dW8OHD1dWVpa+/vprbx9z2HZWPEE52Pzf//2f6uvrmzzB2el06siRIwGqKnBSUlKUl5enwYMH6+TJk3r88cd100036eDBg/J4PIqMjGzyh1idTqc8Ho8kyePxNDuXjX0XGlNdXa1vvvlGXbp0aaez63iN59zc+X57PuLj4336w8PDFRcX5zNmwIABTfbR2NezZ88W57VxH53ZpEmTNHXqVA0YMECfffaZ/umf/kmTJ09WYWGhwsLCmMO/0dDQoAULFuiGG27Q8OHDJanDfn6//PJLK36nNjeHkvTjH/9Y/fr1U0JCgvbv368lS5aopKREr732miTm0B8IO2h3kydP9n49cuRIpaSkqF+/fnr11VetCiHoXO655x7v1yNGjNDIkSN1xRVXaPv27ZowYUIAKwtOmZmZOnjwoD744INAl9JptTSH999/v/frESNGqG/fvpowYYI+++wzXXHFFR1dppVYxmoHvXv3VlhYWJM7EsrLy+VyuQJUVfCIjY3VoEGDdOzYMblcLtXW1qqystJnzLfnyuVyNTuXjX0XGuNwOKwLVI3nfKHvL5fLpYqKCp/+8+fP6/Tp036ZVxu/jwcOHKjevXvr2LFjkpjDb5s3b542bdqk9957T5dffrm3vaN+fm34ndrSHDYnJSVFkny+F5nDtiHstIPIyEiNHj1aBQUF3raGhgYVFBTI7XYHsLLgcPbsWX322Wfq27evRo8erYiICJ+5KikpUWlpqXeu3G63Dhw44PMfT35+vhwOh5KTk71jvr2PxjE2zveAAQPkcrl8zre6ulq7d+/2mbPKykoVFRV5x2zbtk0NDQ3eX6Rut1vvv/++6urqvGPy8/M1ePBg9ezZ0zvmUpnXP//5z/riiy/Ut29fScyh9JdHHMybN0+vv/66tm3b1mTJrqN+fjvz79TvmsPm7Nu3T5J8vhcv5Tn0i0BfIW2rDRs2mKioKJOXl2eKi4vN/fffb2JjY32upr9UPPzww2b79u3m+PHj5sMPPzSpqammd+/epqKiwhjzl1tXk5KSzLZt28zevXuN2+02brfb+/7G2y4nTpxo9u3bZ7Zs2WL69OnT7G2XixcvNocPHzY5OTmd+tbzM2fOmE8++cR88sknRpJ5+umnzSeffGL+9Kc/GWP+cut5bGysefPNN83+/fvNXXfd1eyt59dcc43ZvXu3+eCDD8xVV13lc9t0ZWWlcTqdZsaMGebgwYNmw4YNpmvXrk1umw4PDzdPPfWUOXz4sFm+fHmnuW36QnN45swZ88gjj5jCwkJz/Phxs3XrVnPttdeaq666ypw7d867j0t9DufOnWtiYmLM9u3bfW6L/vrrr71jOurnt7P+Tv2uOTx27JhZuXKl2bt3rzl+/Lh58803zcCBA83NN9/s3celPof+QNhpR88995xJSkoykZGR5vrrrze7du0KdEkBMW3aNNO3b18TGRlpLrvsMjNt2jRz7Ngxb/8333xjfvazn5mePXuarl27mrvvvtucPHnSZx9//OMfzeTJk02XLl1M7969zcMPP2zq6up8xrz33ntm1KhRJjIy0gwcONDk5uZ2xOm1i/fee89IarLNmjXLGPOX288fe+wx43Q6TVRUlJkwYYIpKSnx2ccXX3xh7r33XtO9e3fjcDjMfffdZ86cOeMz5tNPPzU33nijiYqKMpdddpl58sknm9Ty6quvmkGDBpnIyEgzbNgw8/bbb7fbefvThebw66+/NhMnTjR9+vQxERERpl+/fmbOnDlNfulf6nPY3PxJ8vnZ6sif3874O/W75rC0tNTcfPPNJi4uzkRFRZkrr7zSLF682Oc5O8Zc2nPoDyHGGNNxnyMBAAB0LK7ZAQAAViPsAAAAqxF2AACA1Qg7AADAaoQdAABgNcIOAACwGmEHAABYjbADAACsRtgBEFRuueUWLViwwPpjAug4hB0A+B5CQkL0xhtvBLoMAK1A2AEAAFYj7AAIWjU1NXrkkUd02WWXqVu3bkpJSdH27du9/Xl5eYqNjdU777yjoUOHqnv37po0aZJOnjzpHXP+/Hn9/Oc/V2xsrHr16qUlS5Zo1qxZmjJlis+xGhoa9OijjyouLk4ul0srVqzw9vXv31+SdPfddyskJMT7GkDnQNgBELTmzZunwsJCbdiwQfv379ff/d3fadKkSTp69Kh3zNdff62nnnpK//3f/633339fpaWleuSRR7z9//qv/6p169YpNzdXH374oaqrq5tdjnrllVfUrVs37d69W6tWrdLKlSuVn58vSdqzZ48kKTc3VydPnvS+BtA5EHYABKXS0lLl5uZq48aNuummm3TFFVfokUce0Y033qjc3FzvuLq6Oq1Zs0ZjxozRtddeq3nz5qmgoMDb/9xzzykrK0t33323hgwZoueff16xsbFNjjdy5EgtX75cV111lWbOnKkxY8Z499OnTx9JUmxsrFwul/c1gM4hPNAFAEBzDhw4oPr6eg0aNMinvaamRr169fK+7tq1q6644grv6759+6qiokKSVFVVpfLycl1//fXe/rCwMI0ePVoNDQ0++x05cqTP62/vB0DnRtgBEJTOnj2rsLAwFRUVKSwszKeve/fu3q8jIiJ8+kJCQmSMuejjNbefvw1EADonlrEABKVrrrlG9fX1qqio0JVXXumzuVyu77WPmJgYOZ1On2ts6uvr9fHHH190PREREaqvr7/o9wEIPMIOgKA0aNAgTZ8+XTNnztRrr72m48eP66OPPlJ2drbefvvt772f+fPnKzs7W2+++aZKSkr00EMP6csvv1RISMhF1dO/f38VFBTI4/Hoyy+/vNjTARBAhB0AQSs3N1czZ87Uww8/rMGDB2vKlCnas2ePkpKSvvc+lixZonvvvVczZ86U2+1W9+7dlZaWpujo6Iuq5Ve/+pXy8/OVmJioa6655mJPBUAAhZjWLG4DQCfV0NCgoUOH6kc/+pGeeOKJQJcDoANwgTIAq/3pT3/Su+++qx/+8IeqqanR888/r+PHj+vHP/5xoEsD0EFYxgJgtdDQUOXl5em6667TDTfcoAMHDmjr1q0aOnRooEsD0EFYxgIAAFbjkx0AAGA1wg4AALAaYQcAAFiNsAMAAKxG2AEAAFYj7AAAAKsRdgAAgNUIOwAAwGr/H5s977YU0olZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df_resume['lenght'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume=df_resume.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume_filtred=df_resume[df_resume['lenght']<10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3071, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume_filtred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engineering and Construction        353\n",
       "Arts, Culture, and Entertainment    346\n",
       "Sales and Commerce                  345\n",
       "Finance and Accounting              342\n",
       "Health and Life Sciences            256\n",
       "Marketing and Communication         215\n",
       "Administration and Management       204\n",
       "Human Resources                     157\n",
       "Transport and Logistics             143\n",
       "Tourism and Hospitality             138\n",
       "Law and Legal                       131\n",
       "Education and Training              129\n",
       "Personal and Community Services     127\n",
       "Technology and IT                   114\n",
       "Science and Research                 71\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume_filtred['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the score\n",
    "resuls_dict = {'model': [], 'score': []}\n",
    "results_df = pd.DataFrame(resuls_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un échantillon aléatoire de 20% du dataset complet\n",
    "sample_df = df_resume_filtred.sample(frac=0.2, random_state=42)\n",
    "full_df=df_resume_filtred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for strategy 'stratified': 0.08\n",
      "Accuracy for strategy 'most_frequent': 0.09\n",
      "Accuracy for strategy 'uniform': 0.06\n",
      "Accuracy for strategy 'prior': 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/2829911646.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/2829911646.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/2829911646.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/2829911646.py:27: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division en deux set d'entraînement et de test sur tout le dataset\n",
    "X=full_df['Resume']\n",
    "y=full_df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dictionnaire pour stocker les modèles avec différentes stratégies\n",
    "dummy_models = {}\n",
    "dummy_strategies = ['stratified', 'most_frequent', 'uniform', 'prior']\n",
    "\n",
    "\n",
    "for strategy in dummy_strategies:\n",
    "    dummy_model = DummyClassifier(strategy=strategy, random_state=42)\n",
    "    dummy_models[strategy] = dummy_model\n",
    "\n",
    "# Entraînez et évaluez les modèles\n",
    "for strategy, model in dummy_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy for strategy '{strategy}': {accuracy:.2f}\")\n",
    "    new_line = {'model': f\"DummyClassifier with '{strategy}' strategy\" , 'score': round(accuracy,2)}\n",
    "    results_df = results_df.append(new_line, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6357723577235772\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "   Administration and Management       0.48      0.52      0.50        44\n",
      "Arts, Culture, and Entertainment       0.55      0.67      0.60        70\n",
      "          Education and Training       0.78      0.60      0.68        30\n",
      "    Engineering and Construction       0.63      0.73      0.67        78\n",
      "          Finance and Accounting       0.77      0.90      0.83        69\n",
      "        Health and Life Sciences       0.53      0.63      0.57        43\n",
      "                 Human Resources       0.90      0.82      0.86        34\n",
      "                   Law and Legal       0.71      0.48      0.57        25\n",
      "     Marketing and Communication       0.77      0.75      0.76        48\n",
      " Personal and Community Services       0.80      0.30      0.43        27\n",
      "              Sales and Commerce       0.51      0.71      0.60        56\n",
      "            Science and Research       0.67      0.12      0.20        17\n",
      "           Technology and IT           0.29      0.08      0.12        26\n",
      "         Tourism and Hospitality       0.95      0.83      0.88        23\n",
      "         Transport and Logistics       0.45      0.40      0.43        25\n",
      "\n",
      "                        accuracy                           0.64       615\n",
      "                       macro avg       0.65      0.57      0.58       615\n",
      "                    weighted avg       0.64      0.64      0.62       615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/2292701346.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division en deux set d'entraînement et de test sur tout le dataset\n",
    "X=full_df['Resume']\n",
    "y=full_df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Création d'une représentation TF-IDF des textes\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entraînement\n",
    "logistic_regression_model = LogisticRegression(max_iter=500)\n",
    "logistic_regression_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict\n",
    "predictions = logistic_regression_model.predict(X_test_tfidf)\n",
    "\n",
    "# evaluation\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "new_line = {'model': \"LogisticRegression with TF-IDF\" , 'score': round(accuracy,2)}\n",
    "results_df = results_df.append(new_line, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification with TF-IDF and Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5886178861788618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/3273922763.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division en deux set d'entraînement et de test sur tout le dataset\n",
    "X=full_df['Resume']\n",
    "y=full_df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer une représentation TF-IDF des textes\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entraîner un modèle de forêt d'arbres décisionnels\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "predictions = random_forest_model.predict(X_test_tfidf)\n",
    "\n",
    "# Évaluer la performance du modèle\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "#print(\"Classification Report:\\n\", report)\n",
    "\n",
    "new_line = {'model': \"RandomForestClassifier with TF-IDF\" , 'score': round(accuracy,2)}\n",
    "results_df = results_df.append(new_line, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Baye Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5772357723577236\n",
      "\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "   Administration and Management       0.49      0.52      0.51        44\n",
      "Arts, Culture, and Entertainment       0.51      0.43      0.47        70\n",
      "          Education and Training       0.64      0.53      0.58        30\n",
      "    Engineering and Construction       0.64      0.69      0.67        78\n",
      "          Finance and Accounting       0.70      0.91      0.79        69\n",
      "        Health and Life Sciences       0.52      0.70      0.59        43\n",
      "                 Human Resources       0.96      0.74      0.83        34\n",
      "                   Law and Legal       0.50      0.40      0.44        25\n",
      "     Marketing and Communication       0.72      0.71      0.72        48\n",
      " Personal and Community Services       1.00      0.11      0.20        27\n",
      "              Sales and Commerce       0.38      0.64      0.47        56\n",
      "            Science and Research       0.50      0.12      0.19        17\n",
      "           Technology and IT           0.17      0.12      0.14        26\n",
      "         Tourism and Hospitality       0.95      0.78      0.86        23\n",
      "         Transport and Logistics       0.42      0.32      0.36        25\n",
      "\n",
      "                        accuracy                           0.58       615\n",
      "                       macro avg       0.61      0.51      0.52       615\n",
      "                    weighted avg       0.60      0.58      0.56       615\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/1945132640.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division en deux set d'entraînement et de test sur tout le dataset\n",
    "X=full_df['Resume']\n",
    "y=full_df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Créer le modèle Naive Bayes\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Entraîner le modèle sur les données d'entraînement\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire les étiquettes sur les données de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Afficher les performances du modèle\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", metrics.classification_report(y_test, y_pred))\n",
    "\n",
    "new_line = {'model': \"Naive Baye Model\" ,'score': round(metrics.accuracy_score(y_test, y_pred),2)}\n",
    "results_df = results_df.append(new_line, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/77 [======>.......................] - ETA: 4:54 - loss: 2.6866 - accuracy: 0.0694"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Division en deux set d'entraînement et de test sur tout le dataset\n",
    "X=full_df['Resume']\n",
    "y=full_df['Category']\n",
    "\n",
    "# X=sample_df['Resume']\n",
    "# y=sample_df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenizer to convert text into sequences of integers\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "#Padding to ensure all sequences have the same length\n",
    "max_len = 5000\n",
    "\n",
    "X_padded = tf.keras.preprocessing.sequence.pad_sequences(X_seq, padding='post', maxlen=max_len)\n",
    "\n",
    "# Create the model\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=50, input_length=max_len,mask_zero=True),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    Bidirectional(LSTM(32)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(y.unique()), activation='softmax') # verfifier si len(y.unique() corresponds bien au nombre de categories.\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "epochs=1000\n",
    "model.fit(X_padded, y_labels, epochs=epochs, validation_split=0.2, callbacks=[early_stopping])  # modifier le nombre d'epoch\n",
    "\n",
    "# Evaluate the model on the entire dataset\n",
    "test_loss, test_acc = model.evaluate(X_padded, y_labels)\n",
    "print(\"Accuracy on the entire dataset:\", test_acc)\n",
    "\n",
    "new_line = {'model': \"Neural Network model\" , 'score': round(test_acc,2)}\n",
    "results_df = results_df.append(new_line, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Train model : BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import legacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7043db59bd9c45a392a326d9468f1432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac437f8a37842c3ab949562b5f3ed0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda57c3917124938b62e5d471278086f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03616a365a494ae694a7aa459a6b43ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9029c9ca785b48179f541810d27ecd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger le modèle BERT\n",
    "# model_name = \"bert-base-uncased\"\n",
    "model_name = \"bert-large-uncased\"\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforme les category en nombre\n",
    "labels_dict = {}\n",
    "for idx, label in enumerate(df_resume.Category.unique()):\n",
    "    labels_dict[label] = idx\n",
    "\n",
    "df_resume.Category = df_resume.Category.apply(func=lambda x: labels_dict[x])\n",
    "df_resume['Resume'].fillna('', inplace=True)\n",
    "\n",
    "sample_df = df_resume.sample(frac=0.1, random_state=42) #x% du dataset.\n",
    "#Division des données en ensembles d'entraînement, de validation et de test\n",
    "train_data, test_data = train_test_split(sample_df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenisation avec BERT\n",
    "# Charger le tokenizer BERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# Tokeniser les textes d'entraînement, de validation et de test\n",
    "max_length=100\n",
    "train_tokens = tokenizer(list(train_data['Resume']), truncation=True, padding=True, max_length=max_length, return_tensors=\"tf\")\n",
    "val_tokens = tokenizer(list(val_data['Resume']), truncation=True, padding=True, max_length=max_length, return_tensors=\"tf\")\n",
    "test_tokens = tokenizer(list(test_data['Resume']), truncation=True, padding=True, max_length=max_length, return_tensors=\"tf\")\n",
    "\n",
    "# Extraire les input_ids et attention_masks\n",
    "train_input_ids, train_attention_masks = train_tokens['input_ids'], train_tokens['attention_mask']\n",
    "val_input_ids, val_attention_masks = val_tokens['input_ids'], val_tokens['attention_mask']\n",
    "test_input_ids, test_attention_masks = test_tokens['input_ids'], test_tokens['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier la structure de votre modèle en utilisant le modèle fonctionnel\n",
    "input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "# Incorporer BERT dans votre modèle\n",
    "bert_output = model({'input_ids': input_ids, 'attention_mask': attention_mask}).logits\n",
    "\n",
    "# Ajouter la couche Dense pour la classification\n",
    "#output = tf.keras.layers.Dense(units=len(df_resume['Category'].unique()), activation='softmax')(bert_output)\n",
    "output = tf.keras.layers.Dense(units=len(df_resume['Category'].unique()), activation='softmax')(bert_output)\n",
    "\n",
    "# Créer le modèle fonctionnel\n",
    "classification_model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "# Définir le learning rate initial et la taille du batch\n",
    "initial_learning_rate = 1e-2\n",
    "batch_size = 32\n",
    "\n",
    "# Définir le plan d'apprentissage (learning schedule) avec une décroissance exponentielle\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=len(train_data) // batch_size, decay_rate=0.9, staircase=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle avec l'optimiseur utilisant le plan d'apprentissage\n",
    "classification_model.compile(\n",
    "    # optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    optimizer = legacy.Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir l'arrêt précoce\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Surveiller la perte sur l'ensemble de validation\n",
    "    patience=2,           # Nombre d'époques sans amélioration avant l'arrêt\n",
    "    restore_best_weights=True  # Restaurer les meilleurs poids du modèle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 721s 89s/step - loss: 3.8521 - accuracy: 0.0781 - val_loss: 3.4138 - val_accuracy: 0.0615\n"
     ]
    }
   ],
   "source": [
    "history = classification_model.fit(\n",
    "    {'input_ids': train_input_ids, 'attention_mask': train_attention_masks},\n",
    "    train_data['Category'].values,\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    validation_data=({'input_ids': val_input_ids, 'attention_mask': val_attention_masks}, val_data['Category'].values)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 25s 3s/step - loss: 2.7780 - accuracy: 0.0697\n",
      "Test Accuracy: 0.06965173780918121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_74075/747190639.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(new_line, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle\n",
    "test_metrics = classification_model.evaluate(\n",
    "    {'input_ids': test_input_ids, 'attention_mask': test_attention_masks},\n",
    "    test_data['Category'].values\n",
    ")\n",
    "\n",
    "print(\"Test Accuracy:\", test_metrics[1])\n",
    "\n",
    "new_line = {'model': \"BERT pretrained model\" , 'score': round(test_metrics[1],2)}\n",
    "results_df = results_df.append(new_line, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier with TF-IDF</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression with TF-IDF</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Baye Model</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network model</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DummyClassifier with 'stratified' strategy</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DummyClassifier with 'stratified' strategy</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DummyClassifier with 'most_frequent' strategy</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DummyClassifier with 'prior' strategy</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DummyClassifier with 'most_frequent' strategy</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DummyClassifier with 'prior' strategy</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DummyClassifier with 'uniform' strategy</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DummyClassifier with 'uniform' strategy</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BERT pretrained model</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  score\n",
       "0              RandomForestClassifier with TF-IDF   0.68\n",
       "1                  LogisticRegression with TF-IDF   0.60\n",
       "2                                Naive Baye Model   0.58\n",
       "3                            Neural Network model   0.21\n",
       "4      DummyClassifier with 'stratified' strategy   0.12\n",
       "5      DummyClassifier with 'stratified' strategy   0.12\n",
       "6   DummyClassifier with 'most_frequent' strategy   0.09\n",
       "7           DummyClassifier with 'prior' strategy   0.09\n",
       "8   DummyClassifier with 'most_frequent' strategy   0.09\n",
       "9           DummyClassifier with 'prior' strategy   0.09\n",
       "10        DummyClassifier with 'uniform' strategy   0.07\n",
       "11        DummyClassifier with 'uniform' strategy   0.07\n",
       "12                          BERT pretrained model   0.07"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.sort_values(by='score', ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
